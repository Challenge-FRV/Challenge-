# Estrategia del Modelo CNN - Challenge de ClasificaciÃ³n de Enfermedades Oculares

## ğŸ“Š AnÃ¡lisis del Challenge

- **Objetivo**: Clasificar imÃ¡genes de fondo de ojo en 5 categorÃ­as (Normal, Diabetes, Cataract, Myopia, Glaucoma)
- **Dataset**: 5,078 imÃ¡genes de entrenamiento, 1,088 validaciÃ³n, 1,089 test
- **Baseline a superar**: F1-score = 0.56 (SVM con descriptores clÃ¡sicos)
- **Meta competitiva**: F1-score > 0.80 para asegurar posiciÃ³n ganadora

## ğŸ¯ Estrategia Ganadora

### 1. Transfer Learning con EfficientNetB3
**Â¿Por quÃ© EfficientNet?**
- Estado del arte en eficiencia: mejor precisiÃ³n/costo computacional
- 12M de parÃ¡metros pre-entrenados en ImageNet
- Arquitectura optimizada con compound scaling
- Excelente rendimiento en imÃ¡genes mÃ©dicas

**ImplementaciÃ³n:**
- Modelo base pre-entrenado (sin top layer)
- Fine-tuning en 2 fases:
  - Fase 1: Base congelado, entrenar solo capas superiores (30 Ã©pocas)
  - Fase 2: Descongelar todo, fine-tuning completo (40 Ã©pocas)

### 2. Preprocesamiento Especializado para ImÃ¡genes MÃ©dicas

**TÃ©cnicas aplicadas:**
- **DetecciÃ³n automÃ¡tica del cÃ­rculo del fondo de ojo**: Elimina bordes negros irrelevantes
- **CLAHE (Contrast Limited Adaptive Histogram Equalization)**: Mejora contraste en estructuras vasculares
- **NormalizaciÃ³n**: Escala a [0,1] para estabilidad del entrenamiento
- **Redimensionamiento inteligente**: 224x224 con interpolaciÃ³n Lanczos

**Impacto esperado:** +10-15% en F1-score vs. sin preprocesamiento

### 3. Data Augmentation Agresivo

**Transformaciones aplicadas (con Albumentations):**
- Rotaciones: Â±180Â° (prob=0.7) - crucial para imÃ¡genes mÃ©dicas
- Flips horizontal/vertical: (prob=0.5)
- Ajustes de brillo/contraste: Â±30% (prob=0.7)
- Gaussian Blur: kernel 3-5 (prob=0.3)
- Gaussian Noise: (prob=0.3)
- Transformaciones afines: shift, scale (prob=0.5)
- Ajustes HSV: hue/sat/val (prob=0.5)

**Beneficio:** Reduce overfitting, aumenta generalizaciÃ³n, simula variabilidad real

### 4. Class Balancing

**Problema detectado:** Dataset probablemente desbalanceado
**SoluciÃ³n:** Pesos de clase calculados con `sklearn.compute_class_weight`
**Efecto:** El modelo presta mÃ¡s atenciÃ³n a clases minoritarias

### 5. Arquitectura Personalizada

```
Input (224, 224, 3)
    â†“
EfficientNetB3 Pre-entrenado (base)
    â†“
GlobalAveragePooling
    â†“
BatchNormalization + Dropout(0.3)
    â†“
Dense(512, ReLU) + L2 Regularization
    â†“
BatchNormalization + Dropout(0.3)
    â†“
Dense(256, ReLU) + L2 Regularization
    â†“
Dropout(0.15)
    â†“
Dense(5, Softmax)
```

**RegularizaciÃ³n agresiva:**
- Dropout: 0.3, 0.3, 0.15
- L2 regularization: 0.001
- Batch Normalization en cada etapa

### 6. Test-Time Augmentation (TTA)

**Concepto:** Predecir mÃºltiples versiones augmentadas de cada imagen de test
**ImplementaciÃ³n:** 8 predicciones por imagen con diferentes augmentations
**Resultado:** Promedio de probabilidades para predicciÃ³n final mÃ¡s robusta
**Mejora esperada:** +3-5% en F1-score

### 7. Ensemble de Modelos (Opcional)

**Arquitecturas:**
1. EfficientNetB3 (modelo principal)
2. ResNet50V2 (modelo secundario)

**CombinaciÃ³n:** Promedio ponderado (60% EfficientNet, 40% ResNet)
**Ventaja:** Diferentes arquitecturas capturan diferentes patrones
**Mejora esperada:** +2-4% adicional en F1-score

## ğŸš€ Ventajas Competitivas

### vs. Baseline (SVM)
- **Transfer Learning**: Aprovecha 12M parÃ¡metros pre-entrenados vs. entrenar desde cero
- **Representaciones profundas**: CNNs aprenden caracterÃ­sticas jerÃ¡rquicas vs. descriptores fijos
- **End-to-end learning**: OptimizaciÃ³n conjunta de features y clasificador

### vs. Otros Competidores
- **Preprocesamiento mÃ©dico especializado**: No solo usar imÃ¡genes raw
- **TTA**: MayorÃ­a no lo implementa por costo computacional
- **Ensemble**: Duplica tiempo de entrenamiento pero vale la pena
- **Fine-tuning en 2 fases**: Mejor convergencia que fine-tuning directo
- **Class balancing**: Crucial para F1-score macro

## ğŸ“ˆ Rendimiento Esperado

| MÃ©trica | Baseline | Nuestro Modelo | Mejora |
|---------|----------|----------------|--------|
| F1-score (test) | 0.56 | **0.82-0.88** | +46-57% |
| Accuracy | ~0.60 | **0.85-0.90** | +42-50% |
| AUC | ~0.70 | **0.92-0.95** | +31-36% |

## ğŸ”§ Optimizaciones Implementadas

1. **Learning Rate Scheduling**: ReduceLROnPlateau (factor=0.5, patience=5)
2. **Early Stopping**: Patience=15 Ã©pocas, restore best weights
3. **Model Checkpointing**: Guarda mejor modelo segÃºn val_loss
4. **Batch Size**: 16 (balance entre memoria y convergencia)
5. **Optimizador**: Adam con LR adaptativo (1e-4 â†’ 1e-5)

## ğŸ“ Fundamentos del Curso Aplicados

### Conceptos utilizados:
- âœ… **CNNs**: Arquitectura principal
- âœ… **Transfer Learning**: EfficientNet/ResNet pre-entrenados
- âœ… **Data Augmentation**: Rotaciones, flips, transformaciones
- âœ… **Filtros**: Convoluciones en la CNN
- âœ… **Operaciones morfolÃ³gicas**: DetecciÃ³n de contornos para preprocesamiento
- âœ… **Aprendizaje supervisado**: ClasificaciÃ³n con etiquetas
- âœ… **SVM**: Baseline comparativo
- âœ… **Random Forest**: Alternativa descartada (CNNs superiores)
- âœ… **Descriptores de color/textura**: ImplÃ­citos en CNNs
- âœ… **HOG/SIFT**: Conceptos base de features aprendidas por CNNs

### TÃ©cnicas avanzadas opcionales:
- ğŸ”¥ **Focal Loss**: Para clases muy desbalanceadas
- ğŸ”€ **Mixup**: RegularizaciÃ³n mediante mezcla de imÃ¡genes
- ğŸ¯ **Attention Mechanisms**: Enfoque en regiones relevantes

## ğŸ’¡ Recomendaciones para EjecuciÃ³n

1. **Hardware recomendado**: GPU con â‰¥6GB VRAM (Google Colab funciona)
2. **Tiempo de entrenamiento**:
   - Con GPU: 2-4 horas (EfficientNet completo)
   - Con CPU: 12-20 horas
3. **Orden de implementaciÃ³n**:
   - Primero: Solo EfficientNet + TTA (mÃ¡s rÃ¡pido, ya muy bueno)
   - Luego: Agregar ResNet para ensemble (si hay tiempo)
4. **Debugging**: Probar con subset pequeÃ±o primero (100 imÃ¡genes)

## ğŸ† Claves para Ganar la CompeticiÃ³n

1. âœ… **Calidad > Cantidad**: Preprocesamiento especializado es crucial
2. âœ… **TTA es oro**: Muchos lo omiten, tÃº no
3. âœ… **Fine-tuning en 2 fases**: Evita catastrophic forgetting
4. âœ… **ValidaciÃ³n cuidadosa**: No hacer overfitting en validaciÃ³n
5. âœ… **Ensemble si es posible**: Vale el esfuerzo extra
6. âœ… **ExperimentaciÃ³n**: Probar diferentes learning rates, batch sizes

## ğŸ“¦ Entregables

- âœ… `TestPredictions.csv`: Predicciones finales
- âœ… `MetodoFinalGrupo3.ipynb`: Notebook completo y ejecutable
- âœ… Modelos guardados: `efficientnet_fundus_final.h5`, opcionalmente `resnet_fundus_final.h5`

---

**Â¡Buena suerte! Con este enfoque, deberÃ­as estar en el top 3 de la competiciÃ³n.** ğŸ¯
